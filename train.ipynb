{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not api_key:\n",
    "    api_key = input(\"Please enter your Gemini API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional\n",
    "\n",
    "class GoogleGenerativeAI(LLM):\n",
    "    def _call(self, prompt: str, stop: Optional[list] = None) -> str:\n",
    "        \"\"\"Call the Google Generative AI model with the prompt.\"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"google_generative_ai\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHRIVED\\AppData\\Local\\Temp\\ipykernel_26588\\1090379825.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=google_llm, prompt=template)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Instantiate the custom LLM\n",
    "google_llm = GoogleGenerativeAI()\n",
    "\n",
    "# Define a prompt template\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"{topic}\",\n",
    ")\n",
    "\n",
    "# Create an LLM Chain\n",
    "chain = LLMChain(llm=google_llm, prompt=template)\n",
    "\n",
    "# Run the chain example\n",
    "# response = chain.run(\"quantum mechanics\")\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"\"\"You are a nice AI powered chat bot for medical advice. \n",
    "                If the patient is in emergency, suggest them to call the emergency services. \n",
    "                Otherwise, provide them with the best possible medical advice, with possible causes of the problem. \n",
    "                You can also provide them with the nearest hospital or clinic.\n",
    "                If the query is not related to medical advice, answer a phrase like this: I am ChatBot that provides Medical advice. Therefore I need to ask if you require any medical assistance. Is there anything else I can help you with medically?.\n",
    "                Do not provide any medical advice that is not safe or is not recommended by a professional doctor.\n",
    "                Do not give advice related to big problems like cancer, heart attack, etc, unless there is a very high probability of the problem\n",
    "                Don't say that the bot would same something like this, just provide the output.\n",
    "                Do not include any personal information in the response.\n",
    "                Do not say that you can't provide medical advice. Instead provide some basic advice and suggest them to visit a doctor.\"\"\"),\n",
    "    ('human', '{user_input}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot(user_input: str) -> str:\n",
    "    messages = chat_prompt.format_prompt(user_input=user_input)\n",
    "    response = chain.run(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headaches are a common ailment with many potential causes, ranging from stress and dehydration to sinus infections or eye strain.\n",
      "Since I cannot diagnose, I recommend you drink plenty of water, rest in a quiet, dark room, and apply a cool compress to your forehead.\n",
      "If the headache is severe, persists for an extended period, or is accompanied by other symptoms like fever, stiff neck, vision changes, or numbness, please seek immediate medical attention.\n",
      "You should contact your doctor or go to the nearest urgent care facility or hospital for proper diagnosis and treatment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chat_bot(\"I have a headache\").replace(\".  \", \".\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
